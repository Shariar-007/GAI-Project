{
  "issue_id": 653,
  "issue_url": "https://github.com/jhy/jsoup/issues/653",
  "title": "Support xpath 2.0 or greater",
  "description": "<p dir=\"auto\">It would be fine if jsoup could support xpath queries inherently. There is a xpath extension called \"xsoup\" but this extension doesn't cover the whole xpath specification. <a href=\"https://github.com/code4craft/xsoup\">https://github.com/code4craft/xsoup</a></p>\n<p dir=\"auto\">I already tried using saxon in combination with jsoup (converting jsoup document to w3c document) to get full xpath support. This works but using the w3c document object model you get further problems while getting the original inner html for a node as you can see in my question on sf <a href=\"http://stackoverflow.com/questions/33635398/how-to-get-html-from-a-org-w3c-dom-node-in-java\" rel=\"nofollow\">http://stackoverflow.com/questions/33635398/how-to-get-html-from-a-org-w3c-dom-node-in-java</a></p>\n<p dir=\"auto\">I think if jsoup would support xpath many companies and developers would only use jsoup for data extraction and xpath purposes, due to the fact that jsoup offers one of the best parsing-engines for parsing malformed html documents (like many websites or html documents are).</p>",
  "description_text": "It would be fine if jsoup could support xpath queries inherently. There is a xpath extension called \"xsoup\" but this extension doesn't cover the whole xpath specification. https://github.com/code4craft/xsoup\nI already tried using saxon in combination with jsoup (converting jsoup document to w3c document) to get full xpath support. This works but using the w3c document object model you get further problems while getting the original inner html for a node as you can see in my question on sf http://stackoverflow.com/questions/33635398/how-to-get-html-from-a-org-w3c-dom-node-in-java\nI think if jsoup would support xpath many companies and developers would only use jsoup for data extraction and xpath purposes, due to the fact that jsoup offers one of the best parsing-engines for parsing malformed html documents (like many websites or html documents are)."
}